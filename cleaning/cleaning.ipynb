{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType,IntegerType,DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "#create spark Session\n",
    "spark = SparkSession.builder.appName(\"PF\").config(\"spark.sql.caseSensitive\", \"True\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Account: string, Item: string, Amount: double, Date: date, Transaction Type: string, Categories: string, Categories 2: string, Real Amount: double, Note: string, Subscriptions: boolean, Return: boolean, Account Type: string, Owner: string, Statement Day: double]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read master ledger file, this file will also be the output of this notebook\n",
    "#read using pandas then convert to spark dataframe\n",
    "df_out = spark.createDataFrame(pd.read_excel('../data/other_input/Master Ledger.xlsx',sheet_name=\"Master Ledger\"))\n",
    "#change column type to the appropriate type\n",
    "df_out = df_out.withColumn(\"ID\",col(\"ID\").cast(IntegerType()))\\\n",
    "        .withColumn(\"Amount\",col(\"Amount\").cast(DoubleType()))\\\n",
    "        .withColumn(\"Subscriptions\",col(\"Subscriptions\").cast(BooleanType()))\\\n",
    "        .withColumn(\"Return\",col(\"Return\").cast(BooleanType()))\\\n",
    "        .withColumn(\"Real Amount\",col(\"Real Amount\").cast(DoubleType()))\n",
    "#change format of Date\n",
    "df_out = df_out.withColumn(\"Date\",to_date(col(\"Date\"),\"MM/dd/yyyy\"))\n",
    "\n",
    "#print Schema\n",
    "# df_out.printSchema()\n",
    "\n",
    "#drop all rows that don't have any ID, fill NaN with blank\n",
    "df_out = df_out.dropna(how=\"all\",subset= [\"ID\"]).drop('ID','Limit')\n",
    "df_out = df_out.replace('NaN',\"\")\n",
    "#show dataframe\n",
    "df_out.orderBy(\"ID\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all supplementary inputs\n",
    "acc_meta = spark.read.options(inferSchema='True',header='True').csv('../data/other_input/account_metadata.csv')\n",
    "inv_bal = spark.read.options(inferSchema='True',header='True').csv('../data/other_input/investment_balance.csv')\n",
    "\n",
    "#create a category mapping based on past data to auto-assign category\n",
    "category_map = df_out.groupby(['Account','Item','Categories','Categories 2','Transaction Type']).count().orderBy('count',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all csv files exported from Empower, merge into one spark dataframe\n",
    "path = glob.glob('../data/empower_input/*.csv')\n",
    "emp_data = spark.read.options(inferSchema='True',header='True').csv(path)\n",
    "\n",
    "\n",
    "#add more columns to emp_data (all empower transactions), so that it matches columns in df_out (master ledger)\n",
    "emp_data = emp_data.join(acc_meta,on='Account')\\\n",
    ".drop(\"Limit\")\\\n",
    ".filter(~(col('Account Type') == \"Investment\"))\\\n",
    ".withColumn(\"Item\",col(\"Description\")).drop(\"Description\")\\\n",
    ".withColumn(\"Real Amount\",col(\"Amount\"))\\\n",
    ".withColumn(\"Amount\",abs(col(\"Amount\")))\\\n",
    ".withColumn(\"Transaction Type\",when(col(\"Real Amount\") <0, \"Expense\").otherwise(\"Income\"))\\\n",
    ".drop(\"Category\")\\\n",
    ".withColumn(\"Owner\",lit(None))\\\n",
    ".withColumn(\"Subscriptions\",lit(False))\\\n",
    ".withColumn(\"Return\",lit(False))\\\n",
    ".drop(\"Tags\")\\\n",
    "\n",
    "#print schema and show\n",
    "# emp_data.printSchema()\n",
    "# emp_data.orderBy(\"Date\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the latest date in master ledger file\n",
    "max_date = df_out.select(max(\"Date\")).first()[0]\n",
    "\n",
    "# union master ledger with empower, where the empower dataframe is filtered on max_date - 5. \n",
    "# This is to ensure it captures all transactions, because sometimes the transactions are updated few days after, so 5 days is a good limit. \n",
    "df_out = df_out.unionByName(emp_data.filter(col(\"Date\")> lit(max_date)-5), allowMissingColumns=True)\n",
    "df_out = df_out.drop(\"Account Type\",\"Owner\",\"Statement Day\").join(acc_meta, on = 'Account').na.fill(\"\")\n",
    "\n",
    "#auto-assign category using category mapping \n",
    "category_map = df_out.filter(col(\"Categories\") == lit(\"\")).drop('Categories','Categories 2').join(category_map, on=['Account','Item','Transaction Type'], how='left')\n",
    "df_out = df_out.filter(~(col(\"Categories\") == lit(\"\"))).unionByName(category_map, allowMissingColumns=True).drop('count')\n",
    "\n",
    "#further drop duplicates, in case the Note column are already filled using window partition\n",
    "#group all transactions which have the same date, account, item and amount into a partition, then assign row number\n",
    "#if any of them has row_number value higher than 1, and their Note columns is blank, indicate these as dup and filter them out\n",
    "window = Window.partitionBy(['Date','Account','Item','Real Amount']).orderBy(col(\"Note\").desc())\n",
    "df_out = df_out.withColumn(\"row_number\",row_number().over(window))\\\n",
    "    .withColumn('dup',when((col('row_number')>1) & (col('Note') == \"\"),True).otherwise(False))\\\n",
    "    .filter(col('dup') == False)\\\n",
    "    .drop(\"row_number\",\"dup\")\n",
    "    \n",
    "\n",
    "# check investment accounts balance, insert transactions to change \n",
    "df_inv_sum = df_out.filter(col('Account Type') == 'Investment')\\\n",
    "    .groupBy('Account')\\\n",
    "    .agg(sum('Real Amount').alias(\"Old Balance\"))\\\n",
    "    .join(inv_bal, on='Account')\\\n",
    "    .withColumn('Real Amount', col('Balance')- col('Old Balance'))\\\n",
    "    .filter(col('Real Amount') != 0)\\\n",
    "    .withColumn('Item', lit('Adjustment'))\\\n",
    "    .withColumn('Amount', abs(col('Real Amount')))\\\n",
    "    .withColumn('Date', col('Last Updated'))\\\n",
    "    .withColumn('Categories', lit('Transactional'))\\\n",
    "    .withColumn('Categories 2', lit('Transactional'))\\\n",
    "    .withColumn('Transaction Type', when(col('Real Amount')>0,lit('Income 2')).otherwise(lit('Expense 2')))\\\n",
    "    .withColumn('Note', lit(None))\\\n",
    "    .withColumn('Subscriptions', lit(False))\\\n",
    "    .withColumn('Return', lit(False))\\\n",
    "    .join(acc_meta, on='Account')\\\n",
    "    .drop('Last Updated','Balance', 'Old Balance')\n",
    "\n",
    "df_out = df_out.unionByName(df_inv_sum).orderBy(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv and add column ID\n",
    "df_out.toPandas().to_csv(\"../data/output/out.csv\", index_label=\"ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
